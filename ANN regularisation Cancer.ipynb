{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47974215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a6922b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('cancer_classification.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c848159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51dfa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    357\n",
       "0.0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d118690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='target',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed81c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1].values\n",
    "Y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795db90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98aa2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de40b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1: initialize model\n",
    "ann=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c827d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "15/15 [==============================] - 2s 27ms/step - loss: 0.7319 - val_loss: 0.6396\n",
      "Epoch 2/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.5650 - val_loss: 0.5280\n",
      "Epoch 3/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4561 - val_loss: 0.4377\n",
      "Epoch 4/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.3725 - val_loss: 0.3632\n",
      "Epoch 5/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.3011 - val_loss: 0.2958\n",
      "Epoch 6/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2382 - val_loss: 0.2403\n",
      "Epoch 7/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1872 - val_loss: 0.2009\n",
      "Epoch 8/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1509 - val_loss: 0.1733\n",
      "Epoch 9/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1264 - val_loss: 0.1540\n",
      "Epoch 10/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.1386\n",
      "Epoch 11/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0957 - val_loss: 0.1271\n",
      "Epoch 12/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0857 - val_loss: 0.1152\n",
      "Epoch 13/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0782 - val_loss: 0.1059\n",
      "Epoch 14/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0721 - val_loss: 0.0994\n",
      "Epoch 15/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0673 - val_loss: 0.0955\n",
      "Epoch 16/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0638 - val_loss: 0.0929\n",
      "Epoch 17/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0600 - val_loss: 0.0887\n",
      "Epoch 18/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0575 - val_loss: 0.0871\n",
      "Epoch 19/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.0856\n",
      "Epoch 20/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0527 - val_loss: 0.0860\n",
      "Epoch 21/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0510 - val_loss: 0.0854\n",
      "Epoch 22/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0490 - val_loss: 0.0852\n",
      "Epoch 23/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0472 - val_loss: 0.0838\n",
      "Epoch 24/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0459 - val_loss: 0.0822\n",
      "Epoch 25/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0816\n",
      "Epoch 26/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0435 - val_loss: 0.0815\n",
      "Epoch 27/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0422 - val_loss: 0.0821\n",
      "Epoch 28/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0834\n",
      "Epoch 29/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0843\n",
      "Epoch 30/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0392 - val_loss: 0.0814\n",
      "Epoch 31/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0792\n",
      "Epoch 32/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0369 - val_loss: 0.0797\n",
      "Epoch 33/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0360 - val_loss: 0.0790\n",
      "Epoch 34/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0351 - val_loss: 0.0786\n",
      "Epoch 35/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.0803\n",
      "Epoch 36/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0335 - val_loss: 0.0799\n",
      "Epoch 37/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.0815\n",
      "Epoch 38/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0317 - val_loss: 0.0832\n",
      "Epoch 39/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0826\n",
      "Epoch 40/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0302 - val_loss: 0.0833\n",
      "Epoch 41/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.0840\n",
      "Epoch 42/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.0824\n",
      "Epoch 43/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0281 - val_loss: 0.0838\n",
      "Epoch 44/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0823\n",
      "Epoch 45/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0808\n",
      "Epoch 46/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.0832\n",
      "Epoch 47/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0818\n",
      "Epoch 48/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0839\n",
      "Epoch 49/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0861\n",
      "Epoch 50/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0858\n",
      "Epoch 51/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0860\n",
      "Epoch 52/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0915\n",
      "Epoch 53/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0868\n",
      "Epoch 54/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0885\n",
      "Epoch 55/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0903\n",
      "Epoch 56/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0888\n",
      "Epoch 57/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0876\n",
      "Epoch 58/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0905\n",
      "Epoch 59/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0959\n",
      "Epoch 60/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0867\n",
      "Epoch 61/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0916\n",
      "Epoch 62/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0978\n",
      "Epoch 63/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.1005\n",
      "Epoch 64/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0976\n",
      "Epoch 65/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0973\n",
      "Epoch 66/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0993\n",
      "Epoch 67/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0981\n",
      "Epoch 68/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0949\n",
      "Epoch 69/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.1005\n",
      "Epoch 70/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.1013\n",
      "Epoch 71/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.1030\n",
      "Epoch 72/600\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.1070\n",
      "Epoch 73/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.1054\n",
      "Epoch 74/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.1070\n",
      "Epoch 75/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1076\n",
      "Epoch 76/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.1091\n",
      "Epoch 77/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.1077\n",
      "Epoch 78/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.1108\n",
      "Epoch 79/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.1099\n",
      "Epoch 80/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 0.1126\n",
      "Epoch 81/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.1114\n",
      "Epoch 82/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.1142\n",
      "Epoch 83/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.1148\n",
      "Epoch 84/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.1163\n",
      "Epoch 85/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.1159\n",
      "Epoch 86/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.1181\n",
      "Epoch 87/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.1200\n",
      "Epoch 88/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.1190\n",
      "Epoch 89/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.1218\n",
      "Epoch 90/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.1208\n",
      "Epoch 91/600\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.1273\n",
      "Epoch 92/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.1270\n",
      "Epoch 93/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.1256\n",
      "Epoch 94/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.1284\n",
      "Epoch 95/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.1275\n",
      "Epoch 96/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.1298\n",
      "Epoch 97/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.1294\n",
      "Epoch 98/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.1303\n",
      "Epoch 99/600\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.1328\n",
      "Epoch 100/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.1327\n",
      "Epoch 101/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0028 - val_loss: 0.1344\n",
      "Epoch 102/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.1286\n",
      "Epoch 103/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.1291\n",
      "Epoch 104/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.1347\n",
      "Epoch 105/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.1363\n",
      "Epoch 106/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.1377\n",
      "Epoch 107/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.1385\n",
      "Epoch 108/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.1384\n",
      "Epoch 109/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.1415\n",
      "Epoch 110/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.1414\n",
      "Epoch 111/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.1411\n",
      "Epoch 112/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.1448\n",
      "Epoch 113/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.1451\n",
      "Epoch 114/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1455\n",
      "Epoch 115/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1482\n",
      "Epoch 116/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.1456\n",
      "Epoch 117/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.1472\n",
      "Epoch 118/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.1498\n",
      "Epoch 119/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.1486\n",
      "Epoch 120/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.1503\n",
      "Epoch 121/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.1519\n",
      "Epoch 122/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.1520\n",
      "Epoch 123/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.1542\n",
      "Epoch 124/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.1515\n",
      "Epoch 125/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.1522\n",
      "Epoch 126/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1512\n",
      "Epoch 127/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.1494\n",
      "Epoch 128/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.1510\n",
      "Epoch 129/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.1540\n",
      "Epoch 130/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.1580\n",
      "Epoch 131/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.1577\n",
      "Epoch 132/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.1590\n",
      "Epoch 133/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.7764e-04 - val_loss: 0.1606\n",
      "Epoch 134/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.7367e-04 - val_loss: 0.1584\n",
      "Epoch 135/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.3241e-04 - val_loss: 0.1608\n",
      "Epoch 136/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 9.0042e-04 - val_loss: 0.1618\n",
      "Epoch 137/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8.9452e-04 - val_loss: 0.1640\n",
      "Epoch 138/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 8.6067e-04 - val_loss: 0.1630\n",
      "Epoch 139/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 8.3084e-04 - val_loss: 0.1640\n",
      "Epoch 140/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 8.1921e-04 - val_loss: 0.1655\n",
      "Epoch 141/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.8827e-04 - val_loss: 0.1653\n",
      "Epoch 142/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.7730e-04 - val_loss: 0.1647\n",
      "Epoch 143/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.4969e-04 - val_loss: 0.1658\n",
      "Epoch 144/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.3419e-04 - val_loss: 0.1676\n",
      "Epoch 145/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.3265e-04 - val_loss: 0.1682\n",
      "Epoch 146/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.0209e-04 - val_loss: 0.1678\n",
      "Epoch 147/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.9711e-04 - val_loss: 0.1697\n",
      "Epoch 148/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.7389e-04 - val_loss: 0.1714\n",
      "Epoch 149/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.6572e-04 - val_loss: 0.1721\n",
      "Epoch 150/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.3126e-04 - val_loss: 0.1714\n",
      "Epoch 151/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.1765e-04 - val_loss: 0.1722\n",
      "Epoch 152/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.0812e-04 - val_loss: 0.1718\n",
      "Epoch 153/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.9668e-04 - val_loss: 0.1727\n",
      "Epoch 154/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.7599e-04 - val_loss: 0.1734\n",
      "Epoch 155/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.6124e-04 - val_loss: 0.1738\n",
      "Epoch 156/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.4784e-04 - val_loss: 0.1740\n",
      "Epoch 157/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.3611e-04 - val_loss: 0.1741\n",
      "Epoch 158/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.2320e-04 - val_loss: 0.1750\n",
      "Epoch 159/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1459e-04 - val_loss: 0.1768\n",
      "Epoch 160/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.0296e-04 - val_loss: 0.1772\n",
      "Epoch 161/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9097e-04 - val_loss: 0.1783\n",
      "Epoch 162/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.8246e-04 - val_loss: 0.1793\n",
      "Epoch 163/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.6922e-04 - val_loss: 0.1791\n",
      "Epoch 164/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.6194e-04 - val_loss: 0.1792\n",
      "Epoch 165/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.5307e-04 - val_loss: 0.1797\n",
      "Epoch 166/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.4181e-04 - val_loss: 0.1803\n",
      "Epoch 167/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.3083e-04 - val_loss: 0.1808\n",
      "Epoch 168/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1902e-04 - val_loss: 0.1816\n",
      "Epoch 169/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1177e-04 - val_loss: 0.1820\n",
      "Epoch 170/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0051e-04 - val_loss: 0.1827\n",
      "Epoch 171/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.9513e-04 - val_loss: 0.1837\n",
      "Epoch 172/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8684e-04 - val_loss: 0.1838\n",
      "Epoch 173/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7436e-04 - val_loss: 0.1858\n",
      "Epoch 174/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7646e-04 - val_loss: 0.1854\n",
      "Epoch 175/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6138e-04 - val_loss: 0.1861\n",
      "Epoch 176/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5401e-04 - val_loss: 0.1860\n",
      "Epoch 177/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4697e-04 - val_loss: 0.1865\n",
      "Epoch 178/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4016e-04 - val_loss: 0.1869\n",
      "Epoch 179/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3199e-04 - val_loss: 0.1883\n",
      "Epoch 180/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.2417e-04 - val_loss: 0.1883\n",
      "Epoch 181/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.2235e-04 - val_loss: 0.1888\n",
      "Epoch 182/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1330e-04 - val_loss: 0.1899\n",
      "Epoch 183/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1089e-04 - val_loss: 0.1909\n",
      "Epoch 184/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0238e-04 - val_loss: 0.1909\n",
      "Epoch 185/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9736e-04 - val_loss: 0.1910\n",
      "Epoch 186/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9034e-04 - val_loss: 0.1922\n",
      "Epoch 187/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.8601e-04 - val_loss: 0.1923\n",
      "Epoch 188/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7943e-04 - val_loss: 0.1946\n",
      "Epoch 189/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7632e-04 - val_loss: 0.1948\n",
      "Epoch 190/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7217e-04 - val_loss: 0.1969\n",
      "Epoch 191/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6553e-04 - val_loss: 0.1973\n",
      "Epoch 192/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6096e-04 - val_loss: 0.1977\n",
      "Epoch 193/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.5677e-04 - val_loss: 0.1980\n",
      "Epoch 194/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.4983e-04 - val_loss: 0.1986\n",
      "Epoch 195/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.4785e-04 - val_loss: 0.1993\n",
      "Epoch 196/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.4154e-04 - val_loss: 0.1998\n",
      "Epoch 197/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.3733e-04 - val_loss: 0.1997\n",
      "Epoch 198/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.3465e-04 - val_loss: 0.2003\n",
      "Epoch 199/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.3438e-04 - val_loss: 0.2008\n",
      "Epoch 200/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.2702e-04 - val_loss: 0.2018\n",
      "Epoch 201/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.2225e-04 - val_loss: 0.2014\n",
      "Epoch 202/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.1930e-04 - val_loss: 0.2023\n",
      "Epoch 203/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.1375e-04 - val_loss: 0.2024\n",
      "Epoch 204/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.1243e-04 - val_loss: 0.2025\n",
      "Epoch 205/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0699e-04 - val_loss: 0.2033\n",
      "Epoch 206/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0359e-04 - val_loss: 0.2040\n",
      "Epoch 207/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0140e-04 - val_loss: 0.2049\n",
      "Epoch 208/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9892e-04 - val_loss: 0.2050\n",
      "Epoch 209/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9335e-04 - val_loss: 0.2066\n",
      "Epoch 210/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9121e-04 - val_loss: 0.2047\n",
      "Epoch 211/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8867e-04 - val_loss: 0.2046\n",
      "Epoch 212/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8441e-04 - val_loss: 0.2059\n",
      "Epoch 213/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8250e-04 - val_loss: 0.2069\n",
      "Epoch 214/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7828e-04 - val_loss: 0.2062\n",
      "Epoch 215/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7665e-04 - val_loss: 0.2064\n",
      "Epoch 216/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7201e-04 - val_loss: 0.2085\n",
      "Epoch 217/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6901e-04 - val_loss: 0.2099\n",
      "Epoch 218/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6673e-04 - val_loss: 0.2104\n",
      "Epoch 219/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6441e-04 - val_loss: 0.2112\n",
      "Epoch 220/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6130e-04 - val_loss: 0.2116\n",
      "Epoch 221/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5925e-04 - val_loss: 0.2122\n",
      "Epoch 222/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5657e-04 - val_loss: 0.2124\n",
      "Epoch 223/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5428e-04 - val_loss: 0.2128\n",
      "Epoch 224/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5395e-04 - val_loss: 0.2131\n",
      "Epoch 225/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4970e-04 - val_loss: 0.2142\n",
      "Epoch 226/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4869e-04 - val_loss: 0.2150\n",
      "Epoch 227/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4657e-04 - val_loss: 0.2139\n",
      "Epoch 228/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4643e-04 - val_loss: 0.2153\n",
      "Epoch 229/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4337e-04 - val_loss: 0.2157\n",
      "Epoch 230/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3963e-04 - val_loss: 0.2170\n",
      "Epoch 231/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3597e-04 - val_loss: 0.2178\n",
      "Epoch 232/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3746e-04 - val_loss: 0.2182\n",
      "Epoch 233/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3262e-04 - val_loss: 0.2184\n",
      "Epoch 234/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3108e-04 - val_loss: 0.2183\n",
      "Epoch 235/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2788e-04 - val_loss: 0.2189\n",
      "Epoch 236/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2596e-04 - val_loss: 0.2194\n",
      "Epoch 237/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2518e-04 - val_loss: 0.2206\n",
      "Epoch 238/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2287e-04 - val_loss: 0.2204\n",
      "Epoch 239/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2338e-04 - val_loss: 0.2204\n",
      "Epoch 240/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2204e-04 - val_loss: 0.2212\n",
      "Epoch 241/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1860e-04 - val_loss: 0.2217\n",
      "Epoch 242/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1465e-04 - val_loss: 0.2233\n",
      "Epoch 243/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1597e-04 - val_loss: 0.2248\n",
      "Epoch 244/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1489e-04 - val_loss: 0.2217\n",
      "Epoch 245/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1756e-04 - val_loss: 0.2222\n",
      "Epoch 246/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1348e-04 - val_loss: 0.2238\n",
      "Epoch 247/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1021e-04 - val_loss: 0.2247\n",
      "Epoch 248/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0825e-04 - val_loss: 0.2261\n",
      "Epoch 249/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0530e-04 - val_loss: 0.2270\n",
      "Epoch 250/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0340e-04 - val_loss: 0.2270\n",
      "Epoch 251/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0193e-04 - val_loss: 0.2283\n",
      "Epoch 252/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.9843e-05 - val_loss: 0.2281\n",
      "Epoch 253/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.8521e-05 - val_loss: 0.2283\n",
      "Epoch 254/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.7726e-05 - val_loss: 0.2279\n",
      "Epoch 255/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.6782e-05 - val_loss: 0.2283\n",
      "Epoch 256/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.5194e-05 - val_loss: 0.2295\n",
      "Epoch 257/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.4357e-05 - val_loss: 0.2300\n",
      "Epoch 258/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.1811e-05 - val_loss: 0.2300\n",
      "Epoch 259/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.3884e-05 - val_loss: 0.2311\n",
      "Epoch 260/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.9908e-05 - val_loss: 0.2312\n",
      "Epoch 261/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.7755e-05 - val_loss: 0.2321\n",
      "Epoch 262/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.6615e-05 - val_loss: 0.2329\n",
      "Epoch 263/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.5749e-05 - val_loss: 0.2331\n",
      "Epoch 264/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.4424e-05 - val_loss: 0.2333\n",
      "Epoch 265/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.3501e-05 - val_loss: 0.2350\n",
      "Epoch 266/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.1992e-05 - val_loss: 0.2355\n",
      "Epoch 267/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.1792e-05 - val_loss: 0.2356\n",
      "Epoch 268/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.0531e-05 - val_loss: 0.2360\n",
      "Epoch 269/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.0210e-05 - val_loss: 0.2362\n",
      "Epoch 270/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.8337e-05 - val_loss: 0.2368\n",
      "Epoch 271/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.7261e-05 - val_loss: 0.2372\n",
      "Epoch 272/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.6088e-05 - val_loss: 0.2370\n",
      "Epoch 273/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.5532e-05 - val_loss: 0.2372\n",
      "Epoch 274/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.4822e-05 - val_loss: 0.2380\n",
      "Epoch 275/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.4194e-05 - val_loss: 0.2384\n",
      "Epoch 276/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.3781e-05 - val_loss: 0.2382\n",
      "Epoch 277/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.3005e-05 - val_loss: 0.2389\n",
      "Epoch 278/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.1223e-05 - val_loss: 0.2393\n",
      "Epoch 279/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.0141e-05 - val_loss: 0.2389\n",
      "Epoch 280/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 7.0907e-05 - val_loss: 0.2400\n",
      "Epoch 281/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.9726e-05 - val_loss: 0.2404\n",
      "Epoch 282/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.8239e-05 - val_loss: 0.2412\n",
      "Epoch 283/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.7062e-05 - val_loss: 0.2411\n",
      "Epoch 284/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.5600e-05 - val_loss: 0.2421\n",
      "Epoch 285/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.4309e-05 - val_loss: 0.2429\n",
      "Epoch 286/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 6.3779e-05 - val_loss: 0.2433\n",
      "Epoch 287/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.2478e-05 - val_loss: 0.2433\n",
      "Epoch 288/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 6.1466e-05 - val_loss: 0.2435\n",
      "Epoch 289/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.0967e-05 - val_loss: 0.2441\n",
      "Epoch 290/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.9937e-05 - val_loss: 0.2449\n",
      "Epoch 291/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 5.9499e-05 - val_loss: 0.2450\n",
      "Epoch 292/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.8609e-05 - val_loss: 0.2453\n",
      "Epoch 293/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 5.9352e-05 - val_loss: 0.2463\n",
      "Epoch 294/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.7535e-05 - val_loss: 0.2463\n",
      "Epoch 295/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.6934e-05 - val_loss: 0.2474\n",
      "Epoch 296/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.6121e-05 - val_loss: 0.2475\n",
      "Epoch 297/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.5059e-05 - val_loss: 0.2480\n",
      "Epoch 298/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.4482e-05 - val_loss: 0.2484\n",
      "Epoch 299/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.3808e-05 - val_loss: 0.2485\n",
      "Epoch 300/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.3354e-05 - val_loss: 0.2496\n",
      "Epoch 301/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.2624e-05 - val_loss: 0.2495\n",
      "Epoch 302/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.2451e-05 - val_loss: 0.2501\n",
      "Epoch 303/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1278e-05 - val_loss: 0.2503\n",
      "Epoch 304/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.0729e-05 - val_loss: 0.2509\n",
      "Epoch 305/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1035e-05 - val_loss: 0.2515\n",
      "Epoch 306/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9503e-05 - val_loss: 0.2488\n",
      "Epoch 307/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9157e-05 - val_loss: 0.2490\n",
      "Epoch 308/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.8520e-05 - val_loss: 0.2498\n",
      "Epoch 309/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.8025e-05 - val_loss: 0.2506\n",
      "Epoch 310/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.7357e-05 - val_loss: 0.2510\n",
      "Epoch 311/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.6805e-05 - val_loss: 0.2520\n",
      "Epoch 312/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.6175e-05 - val_loss: 0.2526\n",
      "Epoch 313/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.5778e-05 - val_loss: 0.2530\n",
      "Epoch 314/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.5092e-05 - val_loss: 0.2530\n",
      "Epoch 315/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 4.4588e-05 - val_loss: 0.2532\n",
      "Epoch 316/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.3915e-05 - val_loss: 0.2538\n",
      "Epoch 317/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.3758e-05 - val_loss: 0.2540\n",
      "Epoch 318/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.3337e-05 - val_loss: 0.2544\n",
      "Epoch 319/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2728e-05 - val_loss: 0.2551\n",
      "Epoch 320/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.2119e-05 - val_loss: 0.2555\n",
      "Epoch 321/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1963e-05 - val_loss: 0.2559\n",
      "Epoch 322/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.1262e-05 - val_loss: 0.2560\n",
      "Epoch 323/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0909e-05 - val_loss: 0.2564\n",
      "Epoch 324/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0329e-05 - val_loss: 0.2567\n",
      "Epoch 325/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.9906e-05 - val_loss: 0.2570\n",
      "Epoch 326/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.9317e-05 - val_loss: 0.2577\n",
      "Epoch 327/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 3.9217e-05 - val_loss: 0.2582\n",
      "Epoch 328/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8529e-05 - val_loss: 0.2599\n",
      "Epoch 329/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8142e-05 - val_loss: 0.2598\n",
      "Epoch 330/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7735e-05 - val_loss: 0.2599\n",
      "Epoch 331/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7225e-05 - val_loss: 0.2602\n",
      "Epoch 332/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6587e-05 - val_loss: 0.2604\n",
      "Epoch 333/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7002e-05 - val_loss: 0.2607\n",
      "Epoch 334/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6250e-05 - val_loss: 0.2609\n",
      "Epoch 335/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5690e-05 - val_loss: 0.2611\n",
      "Epoch 336/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5197e-05 - val_loss: 0.2614\n",
      "Epoch 337/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5157e-05 - val_loss: 0.2619\n",
      "Epoch 338/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4474e-05 - val_loss: 0.2620\n",
      "Epoch 339/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4340e-05 - val_loss: 0.2622\n",
      "Epoch 340/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3734e-05 - val_loss: 0.2631\n",
      "Epoch 341/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3743e-05 - val_loss: 0.2638\n",
      "Epoch 342/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4667e-05 - val_loss: 0.2608\n",
      "Epoch 343/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4333e-05 - val_loss: 0.2614\n",
      "Epoch 344/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3861e-05 - val_loss: 0.2619\n",
      "Epoch 345/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3011e-05 - val_loss: 0.2631\n",
      "Epoch 346/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.2267e-05 - val_loss: 0.2622\n",
      "Epoch 347/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1684e-05 - val_loss: 0.2623\n",
      "Epoch 348/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0980e-05 - val_loss: 0.2632\n",
      "Epoch 349/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0465e-05 - val_loss: 0.2649\n",
      "Epoch 350/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0170e-05 - val_loss: 0.2655\n",
      "Epoch 351/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9718e-05 - val_loss: 0.2657\n",
      "Epoch 352/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9282e-05 - val_loss: 0.2661\n",
      "Epoch 353/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9023e-05 - val_loss: 0.2666\n",
      "Epoch 354/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.8751e-05 - val_loss: 0.2676\n",
      "Epoch 355/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.8401e-05 - val_loss: 0.2677\n",
      "Epoch 356/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.8188e-05 - val_loss: 0.2689\n",
      "Epoch 357/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7793e-05 - val_loss: 0.2693\n",
      "Epoch 358/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7705e-05 - val_loss: 0.2702\n",
      "Epoch 359/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7136e-05 - val_loss: 0.2703\n",
      "Epoch 360/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7192e-05 - val_loss: 0.2700\n",
      "Epoch 361/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6849e-05 - val_loss: 0.2704\n",
      "Epoch 362/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6419e-05 - val_loss: 0.2709\n",
      "Epoch 363/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6133e-05 - val_loss: 0.2717\n",
      "Epoch 364/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.5698e-05 - val_loss: 0.2717\n",
      "Epoch 365/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.5432e-05 - val_loss: 0.2732\n",
      "Epoch 366/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.5036e-05 - val_loss: 0.2729\n",
      "Epoch 367/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.4721e-05 - val_loss: 0.2729\n",
      "Epoch 368/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.4520e-05 - val_loss: 0.2734\n",
      "Epoch 369/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.4190e-05 - val_loss: 0.2735\n",
      "Epoch 370/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.3927e-05 - val_loss: 0.2737\n",
      "Epoch 371/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 2.3752e-05 - val_loss: 0.2737\n",
      "Epoch 372/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.3419e-05 - val_loss: 0.2745\n",
      "Epoch 373/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.3209e-05 - val_loss: 0.2749\n",
      "Epoch 374/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.2946e-05 - val_loss: 0.2747\n",
      "Epoch 375/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.2699e-05 - val_loss: 0.2751\n",
      "Epoch 376/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.2497e-05 - val_loss: 0.2759\n",
      "Epoch 377/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.2224e-05 - val_loss: 0.2761\n",
      "Epoch 378/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.2188e-05 - val_loss: 0.2764\n",
      "Epoch 379/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.2059e-05 - val_loss: 0.2769\n",
      "Epoch 380/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.1549e-05 - val_loss: 0.2776\n",
      "Epoch 381/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.1340e-05 - val_loss: 0.2774\n",
      "Epoch 382/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.1253e-05 - val_loss: 0.2779\n",
      "Epoch 383/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0764e-05 - val_loss: 0.2779\n",
      "Epoch 384/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0638e-05 - val_loss: 0.2785\n",
      "Epoch 385/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0385e-05 - val_loss: 0.2786\n",
      "Epoch 386/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0167e-05 - val_loss: 0.2780\n",
      "Epoch 387/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0100e-05 - val_loss: 0.2776\n",
      "Epoch 388/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9727e-05 - val_loss: 0.2779\n",
      "Epoch 389/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9596e-05 - val_loss: 0.2787\n",
      "Epoch 390/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9386e-05 - val_loss: 0.2792\n",
      "Epoch 391/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9264e-05 - val_loss: 0.2795\n",
      "Epoch 392/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8973e-05 - val_loss: 0.2803\n",
      "Epoch 393/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8799e-05 - val_loss: 0.2803\n",
      "Epoch 394/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8566e-05 - val_loss: 0.2808\n",
      "Epoch 395/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8485e-05 - val_loss: 0.2810\n",
      "Epoch 396/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.8199e-05 - val_loss: 0.2814\n",
      "Epoch 397/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8128e-05 - val_loss: 0.2825\n",
      "Epoch 398/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8017e-05 - val_loss: 0.2820\n",
      "Epoch 399/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7917e-05 - val_loss: 0.2823\n",
      "Epoch 400/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7626e-05 - val_loss: 0.2825\n",
      "Epoch 401/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7288e-05 - val_loss: 0.2833\n",
      "Epoch 402/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7207e-05 - val_loss: 0.2836\n",
      "Epoch 403/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6992e-05 - val_loss: 0.2837\n",
      "Epoch 404/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6771e-05 - val_loss: 0.2848\n",
      "Epoch 405/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6575e-05 - val_loss: 0.2853\n",
      "Epoch 406/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6443e-05 - val_loss: 0.2852\n",
      "Epoch 407/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6377e-05 - val_loss: 0.2859\n",
      "Epoch 408/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6180e-05 - val_loss: 0.2854\n",
      "Epoch 409/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5905e-05 - val_loss: 0.2858\n",
      "Epoch 410/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5932e-05 - val_loss: 0.2863\n",
      "Epoch 411/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5729e-05 - val_loss: 0.2860\n",
      "Epoch 412/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5588e-05 - val_loss: 0.2866\n",
      "Epoch 413/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5382e-05 - val_loss: 0.2877\n",
      "Epoch 414/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5242e-05 - val_loss: 0.2881\n",
      "Epoch 415/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5059e-05 - val_loss: 0.2866\n",
      "Epoch 416/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5129e-05 - val_loss: 0.2873\n",
      "Epoch 417/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4988e-05 - val_loss: 0.2874\n",
      "Epoch 418/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4823e-05 - val_loss: 0.2879\n",
      "Epoch 419/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4506e-05 - val_loss: 0.2880\n",
      "Epoch 420/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4572e-05 - val_loss: 0.2882\n",
      "Epoch 421/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4491e-05 - val_loss: 0.2882\n",
      "Epoch 422/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4022e-05 - val_loss: 0.2891\n",
      "Epoch 423/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3994e-05 - val_loss: 0.2886\n",
      "Epoch 424/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3859e-05 - val_loss: 0.2894\n",
      "Epoch 425/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3611e-05 - val_loss: 0.2899\n",
      "Epoch 426/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3496e-05 - val_loss: 0.2902\n",
      "Epoch 427/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3211e-05 - val_loss: 0.2912\n",
      "Epoch 428/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3242e-05 - val_loss: 0.2918\n",
      "Epoch 429/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3096e-05 - val_loss: 0.2921\n",
      "Epoch 430/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2869e-05 - val_loss: 0.2928\n",
      "Epoch 431/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2747e-05 - val_loss: 0.2933\n",
      "Epoch 432/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2640e-05 - val_loss: 0.2933\n",
      "Epoch 433/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2395e-05 - val_loss: 0.2934\n",
      "Epoch 434/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2339e-05 - val_loss: 0.2939\n",
      "Epoch 435/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2214e-05 - val_loss: 0.2936\n",
      "Epoch 436/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2066e-05 - val_loss: 0.2940\n",
      "Epoch 437/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2046e-05 - val_loss: 0.2942\n",
      "Epoch 438/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1898e-05 - val_loss: 0.2945\n",
      "Epoch 439/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1779e-05 - val_loss: 0.2952\n",
      "Epoch 440/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1657e-05 - val_loss: 0.2951\n",
      "Epoch 441/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1576e-05 - val_loss: 0.2956\n",
      "Epoch 442/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.1680e-05 - val_loss: 0.2941\n",
      "Epoch 443/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1806e-05 - val_loss: 0.2950\n",
      "Epoch 444/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1642e-05 - val_loss: 0.2955\n",
      "Epoch 445/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1338e-05 - val_loss: 0.2964\n",
      "Epoch 446/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1129e-05 - val_loss: 0.2973\n",
      "Epoch 447/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0955e-05 - val_loss: 0.2981\n",
      "Epoch 448/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0843e-05 - val_loss: 0.2981\n",
      "Epoch 449/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0677e-05 - val_loss: 0.2989\n",
      "Epoch 450/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0618e-05 - val_loss: 0.2982\n",
      "Epoch 451/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0572e-05 - val_loss: 0.2988\n",
      "Epoch 452/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0437e-05 - val_loss: 0.2997\n",
      "Epoch 453/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0340e-05 - val_loss: 0.3007\n",
      "Epoch 454/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0139e-05 - val_loss: 0.3012\n",
      "Epoch 455/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.0027e-05 - val_loss: 0.3009\n",
      "Epoch 456/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.8685e-06 - val_loss: 0.3015\n",
      "Epoch 457/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.8158e-06 - val_loss: 0.3024\n",
      "Epoch 458/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.7081e-06 - val_loss: 0.3025\n",
      "Epoch 459/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.6325e-06 - val_loss: 0.3029\n",
      "Epoch 460/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.4987e-06 - val_loss: 0.3033\n",
      "Epoch 461/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.3912e-06 - val_loss: 0.3037\n",
      "Epoch 462/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.3161e-06 - val_loss: 0.3037\n",
      "Epoch 463/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.3004e-06 - val_loss: 0.3041\n",
      "Epoch 464/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.1881e-06 - val_loss: 0.3039\n",
      "Epoch 465/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.0601e-06 - val_loss: 0.3042\n",
      "Epoch 466/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 9.0354e-06 - val_loss: 0.3043\n",
      "Epoch 467/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.9584e-06 - val_loss: 0.3048\n",
      "Epoch 468/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.8604e-06 - val_loss: 0.3049\n",
      "Epoch 469/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.7406e-06 - val_loss: 0.3055\n",
      "Epoch 470/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.6694e-06 - val_loss: 0.3057\n",
      "Epoch 471/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 8.5592e-06 - val_loss: 0.3062\n",
      "Epoch 472/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 8.4658e-06 - val_loss: 0.3063\n",
      "Epoch 473/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 8.3694e-06 - val_loss: 0.3065\n",
      "Epoch 474/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 8.3563e-06 - val_loss: 0.3072\n",
      "Epoch 475/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.2643e-06 - val_loss: 0.3069\n",
      "Epoch 476/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.1725e-06 - val_loss: 0.3078\n",
      "Epoch 477/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 8.1037e-06 - val_loss: 0.3065\n",
      "Epoch 478/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.9973e-06 - val_loss: 0.3071\n",
      "Epoch 479/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.9226e-06 - val_loss: 0.3074\n",
      "Epoch 480/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.8270e-06 - val_loss: 0.3082\n",
      "Epoch 481/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.8448e-06 - val_loss: 0.3094\n",
      "Epoch 482/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.7728e-06 - val_loss: 0.3089\n",
      "Epoch 483/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.6373e-06 - val_loss: 0.3097\n",
      "Epoch 484/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.6033e-06 - val_loss: 0.3108\n",
      "Epoch 485/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.4772e-06 - val_loss: 0.3110\n",
      "Epoch 486/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.4126e-06 - val_loss: 0.3115\n",
      "Epoch 487/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.3562e-06 - val_loss: 0.3115\n",
      "Epoch 488/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.2466e-06 - val_loss: 0.3118\n",
      "Epoch 489/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.2045e-06 - val_loss: 0.3121\n",
      "Epoch 490/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.1910e-06 - val_loss: 0.3123\n",
      "Epoch 491/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.2841e-06 - val_loss: 0.3118\n",
      "Epoch 492/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.1852e-06 - val_loss: 0.3125\n",
      "Epoch 493/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 7.0177e-06 - val_loss: 0.3127\n",
      "Epoch 494/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.8683e-06 - val_loss: 0.3135\n",
      "Epoch 495/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.7834e-06 - val_loss: 0.3141\n",
      "Epoch 496/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.7136e-06 - val_loss: 0.3143\n",
      "Epoch 497/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.7015e-06 - val_loss: 0.3150\n",
      "Epoch 498/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 6.5981e-06 - val_loss: 0.3151\n",
      "Epoch 499/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.5360e-06 - val_loss: 0.3153\n",
      "Epoch 500/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.4964e-06 - val_loss: 0.3143\n",
      "Epoch 501/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.4254e-06 - val_loss: 0.3142\n",
      "Epoch 502/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.3563e-06 - val_loss: 0.3147\n",
      "Epoch 503/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.3090e-06 - val_loss: 0.3155\n",
      "Epoch 504/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.2353e-06 - val_loss: 0.3162\n",
      "Epoch 505/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.2280e-06 - val_loss: 0.3153\n",
      "Epoch 506/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.1568e-06 - val_loss: 0.3159\n",
      "Epoch 507/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.0989e-06 - val_loss: 0.3164\n",
      "Epoch 508/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 6.0088e-06 - val_loss: 0.3166\n",
      "Epoch 509/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.9495e-06 - val_loss: 0.3177\n",
      "Epoch 510/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.8881e-06 - val_loss: 0.3181\n",
      "Epoch 511/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.8404e-06 - val_loss: 0.3187\n",
      "Epoch 512/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.8348e-06 - val_loss: 0.3193\n",
      "Epoch 513/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.7781e-06 - val_loss: 0.3190\n",
      "Epoch 514/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.6766e-06 - val_loss: 0.3197\n",
      "Epoch 515/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.6902e-06 - val_loss: 0.3201\n",
      "Epoch 516/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.5705e-06 - val_loss: 0.3202\n",
      "Epoch 517/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.5333e-06 - val_loss: 0.3209\n",
      "Epoch 518/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.4656e-06 - val_loss: 0.3211\n",
      "Epoch 519/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.4659e-06 - val_loss: 0.3214\n",
      "Epoch 520/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.3828e-06 - val_loss: 0.3214\n",
      "Epoch 521/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.3376e-06 - val_loss: 0.3218\n",
      "Epoch 522/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.3236e-06 - val_loss: 0.3225\n",
      "Epoch 523/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.2715e-06 - val_loss: 0.3226\n",
      "Epoch 524/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1914e-06 - val_loss: 0.3224\n",
      "Epoch 525/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1776e-06 - val_loss: 0.3228\n",
      "Epoch 526/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.1190e-06 - val_loss: 0.3225\n",
      "Epoch 527/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.0519e-06 - val_loss: 0.3233\n",
      "Epoch 528/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.0149e-06 - val_loss: 0.3242\n",
      "Epoch 529/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 5.0092e-06 - val_loss: 0.3230\n",
      "Epoch 530/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9518e-06 - val_loss: 0.3236\n",
      "Epoch 531/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.8523e-06 - val_loss: 0.3240\n",
      "Epoch 532/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.9134e-06 - val_loss: 0.3255\n",
      "Epoch 533/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.7893e-06 - val_loss: 0.3252\n",
      "Epoch 534/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.7059e-06 - val_loss: 0.3256\n",
      "Epoch 535/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.6734e-06 - val_loss: 0.3260\n",
      "Epoch 536/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.6848e-06 - val_loss: 0.3247\n",
      "Epoch 537/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.7280e-06 - val_loss: 0.3253\n",
      "Epoch 538/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.6385e-06 - val_loss: 0.3258\n",
      "Epoch 539/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.5828e-06 - val_loss: 0.3272\n",
      "Epoch 540/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.4980e-06 - val_loss: 0.3277\n",
      "Epoch 541/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.4171e-06 - val_loss: 0.3282\n",
      "Epoch 542/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.3788e-06 - val_loss: 0.3283\n",
      "Epoch 543/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.3401e-06 - val_loss: 0.3295\n",
      "Epoch 544/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.3213e-06 - val_loss: 0.3295\n",
      "Epoch 545/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 4.3058e-06 - val_loss: 0.3292\n",
      "Epoch 546/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1842e-06 - val_loss: 0.3298\n",
      "Epoch 547/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1653e-06 - val_loss: 0.3300\n",
      "Epoch 548/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 4.1017e-06 - val_loss: 0.3304\n",
      "Epoch 549/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0815e-06 - val_loss: 0.3309\n",
      "Epoch 550/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0436e-06 - val_loss: 0.3309\n",
      "Epoch 551/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 4.0107e-06 - val_loss: 0.3311\n",
      "Epoch 552/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.9723e-06 - val_loss: 0.3314\n",
      "Epoch 553/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.9411e-06 - val_loss: 0.3318\n",
      "Epoch 554/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.9192e-06 - val_loss: 0.3320\n",
      "Epoch 555/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8755e-06 - val_loss: 0.3320\n",
      "Epoch 556/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8485e-06 - val_loss: 0.3329\n",
      "Epoch 557/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.8150e-06 - val_loss: 0.3330\n",
      "Epoch 558/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7732e-06 - val_loss: 0.3328\n",
      "Epoch 559/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7282e-06 - val_loss: 0.3333\n",
      "Epoch 560/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6885e-06 - val_loss: 0.3338\n",
      "Epoch 561/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6526e-06 - val_loss: 0.3342\n",
      "Epoch 562/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6021e-06 - val_loss: 0.3331\n",
      "Epoch 563/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6371e-06 - val_loss: 0.3342\n",
      "Epoch 564/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.6143e-06 - val_loss: 0.3351\n",
      "Epoch 565/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5559e-06 - val_loss: 0.3352\n",
      "Epoch 566/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.5026e-06 - val_loss: 0.3357\n",
      "Epoch 567/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4595e-06 - val_loss: 0.3365\n",
      "Epoch 568/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4261e-06 - val_loss: 0.3363\n",
      "Epoch 569/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3895e-06 - val_loss: 0.3357\n",
      "Epoch 570/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 3.3745e-06 - val_loss: 0.3364\n",
      "Epoch 571/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.4012e-06 - val_loss: 0.3367\n",
      "Epoch 572/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3497e-06 - val_loss: 0.3370\n",
      "Epoch 573/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.3030e-06 - val_loss: 0.3380\n",
      "Epoch 574/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.2740e-06 - val_loss: 0.3381\n",
      "Epoch 575/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.2256e-06 - val_loss: 0.3387\n",
      "Epoch 576/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1748e-06 - val_loss: 0.3389\n",
      "Epoch 577/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1830e-06 - val_loss: 0.3394\n",
      "Epoch 578/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1192e-06 - val_loss: 0.3399\n",
      "Epoch 579/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.1483e-06 - val_loss: 0.3399\n",
      "Epoch 580/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0888e-06 - val_loss: 0.3401\n",
      "Epoch 581/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0424e-06 - val_loss: 0.3403\n",
      "Epoch 582/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.0143e-06 - val_loss: 0.3401\n",
      "Epoch 583/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9851e-06 - val_loss: 0.3409\n",
      "Epoch 584/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9393e-06 - val_loss: 0.3408\n",
      "Epoch 585/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9170e-06 - val_loss: 0.3412\n",
      "Epoch 586/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.9022e-06 - val_loss: 0.3416\n",
      "Epoch 587/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.8601e-06 - val_loss: 0.3422\n",
      "Epoch 588/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.8620e-06 - val_loss: 0.3425\n",
      "Epoch 589/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.8213e-06 - val_loss: 0.3423\n",
      "Epoch 590/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.8012e-06 - val_loss: 0.3427\n",
      "Epoch 591/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.7886e-06 - val_loss: 0.3431\n",
      "Epoch 592/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.7480e-06 - val_loss: 0.3433\n",
      "Epoch 593/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.7225e-06 - val_loss: 0.3437\n",
      "Epoch 594/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.7169e-06 - val_loss: 0.3443\n",
      "Epoch 595/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.7111e-06 - val_loss: 0.3448\n",
      "Epoch 596/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.7199e-06 - val_loss: 0.3433\n",
      "Epoch 597/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6787e-06 - val_loss: 0.3434\n",
      "Epoch 598/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6365e-06 - val_loss: 0.3442\n",
      "Epoch 599/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.6004e-06 - val_loss: 0.3448\n",
      "Epoch 600/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.5578e-06 - val_loss: 0.3456\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#step2 : input layer\n",
    "ann.add(Dense(units=30,activation='relu'))\n",
    "ann.add(Dense(units=15,activation='relu'))\n",
    "ann.add(Dense(units=1,activation='sigmoid'))\n",
    "#step3: establish connection\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy')#metric parameter not used \n",
    "#because we want to plot loss graph\n",
    "#step4: train model\n",
    "ann.fit(X_train,Y_train,epochs=600,validation_data=(X_test,Y_test))\n",
    "#validation_data=checks the performance after each epoch\n",
    "#step 5 : predict\n",
    "Y_pred=ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37a9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#never restart the kernel while running,accuracy might be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82473678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step6: set threshold\n",
    "Y_pred=Y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "941cf46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(ann.history.history) #store loss in df\n",
    "lossdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5fcb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low training error:low bias\n",
    "#high testing error:high variance\n",
    "#overfitting  training<testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e315798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regularization\n",
    "#EarlyStopping: helps to stop at minimum error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98263d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann=Sequential()\n",
    "ann.add(Dense(units=30,activation='relu'))\n",
    "ann.add(Dense(units=15,activation='relu'))\n",
    "ann.add(Dense(units=1,activation='sigmoid'))\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27a28760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6f481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_loss',mode=\"min\",verbose=1,patience=25)\n",
    "#verbose:0 means silent 1 means display when callbacks takes\n",
    "#action\n",
    "#patience:no. of epochs with no improvement after which \n",
    "#training will be stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9605988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "15/15 [==============================] - 2s 18ms/step - loss: 0.6695 - val_loss: 0.5270\n",
      "Epoch 2/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4408 - val_loss: 0.3888\n",
      "Epoch 3/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3077 - val_loss: 0.3002\n",
      "Epoch 4/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2250 - val_loss: 0.2404\n",
      "Epoch 5/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1723 - val_loss: 0.2005\n",
      "Epoch 6/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1416 - val_loss: 0.1726\n",
      "Epoch 7/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1214 - val_loss: 0.1538\n",
      "Epoch 8/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1072 - val_loss: 0.1412\n",
      "Epoch 9/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0970 - val_loss: 0.1295\n",
      "Epoch 10/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0881 - val_loss: 0.1201\n",
      "Epoch 11/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0815 - val_loss: 0.1117\n",
      "Epoch 12/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0758 - val_loss: 0.1092\n",
      "Epoch 13/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0708 - val_loss: 0.1057\n",
      "Epoch 14/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0667 - val_loss: 0.1045\n",
      "Epoch 15/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0637 - val_loss: 0.1016\n",
      "Epoch 16/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0604 - val_loss: 0.0988\n",
      "Epoch 17/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.0955\n",
      "Epoch 18/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0548 - val_loss: 0.0938\n",
      "Epoch 19/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0525 - val_loss: 0.0936\n",
      "Epoch 20/600\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0505 - val_loss: 0.0894\n",
      "Epoch 21/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0486 - val_loss: 0.0904\n",
      "Epoch 22/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0465 - val_loss: 0.0910\n",
      "Epoch 23/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.0866\n",
      "Epoch 24/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0435 - val_loss: 0.0875\n",
      "Epoch 25/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0417 - val_loss: 0.0864\n",
      "Epoch 26/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0403 - val_loss: 0.0895\n",
      "Epoch 27/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0387 - val_loss: 0.0913\n",
      "Epoch 28/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.0889\n",
      "Epoch 29/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0364 - val_loss: 0.0900\n",
      "Epoch 30/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0348 - val_loss: 0.0897\n",
      "Epoch 31/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.0876\n",
      "Epoch 32/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0327 - val_loss: 0.0898\n",
      "Epoch 33/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0316 - val_loss: 0.0899\n",
      "Epoch 34/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0891\n",
      "Epoch 35/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.0884\n",
      "Epoch 36/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0285 - val_loss: 0.0884\n",
      "Epoch 37/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.0915\n",
      "Epoch 38/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0907\n",
      "Epoch 39/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.0901\n",
      "Epoch 40/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0907\n",
      "Epoch 41/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.0908\n",
      "Epoch 42/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.0916\n",
      "Epoch 43/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0912\n",
      "Epoch 44/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0943\n",
      "Epoch 45/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0930\n",
      "Epoch 46/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0951\n",
      "Epoch 47/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0951\n",
      "Epoch 48/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0958\n",
      "Epoch 49/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0981\n",
      "Epoch 50/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0988\n",
      "Epoch 50: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d24f933a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train,Y_train,epochs=600,validation_data=(X_test,Y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "678ddf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.669528</td>\n",
       "      <td>0.527004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440757</td>\n",
       "      <td>0.388837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307747</td>\n",
       "      <td>0.300186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225018</td>\n",
       "      <td>0.240379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172326</td>\n",
       "      <td>0.200505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.669528  0.527004\n",
       "1  0.440757  0.388837\n",
       "2  0.307747  0.300186\n",
       "3  0.225018  0.240379\n",
       "4  0.172326  0.200505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(ann.history.history)\n",
    "lossdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dab858d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.020455</td>\n",
       "      <td>0.095135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.095074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.018709</td>\n",
       "      <td>0.095766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.098107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.098770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  val_loss\n",
       "45  0.020455  0.095135\n",
       "46  0.019551  0.095074\n",
       "47  0.018709  0.095766\n",
       "48  0.018061  0.098107\n",
       "49  0.017412  0.098770"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38147952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1fb1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout\n",
    "#regularization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "#referrs to dropping out of nodes in neural network\n",
    "#it reduces overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45e41dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann=Sequential()\n",
    "ann.add(Dense(units=30,activation='relu'))\n",
    "ann.add(Dropout(rate=0.5))\n",
    "ann.add(Dense(units=15,activation='relu'))\n",
    "ann.add(Dropout(rate=0.5))\n",
    "#dropout to be addded after hidden layer not after output\n",
    "ann.add(Dense(units=1,activation='sigmoid'))\n",
    "ann.compile(optimizer='adam',loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00b0b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "15/15 [==============================] - 1s 18ms/step - loss: 0.6626 - val_loss: 0.5807\n",
      "Epoch 2/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.4912\n",
      "Epoch 3/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4767 - val_loss: 0.4188\n",
      "Epoch 4/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4278 - val_loss: 0.3623\n",
      "Epoch 5/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3788 - val_loss: 0.3190\n",
      "Epoch 6/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3551 - val_loss: 0.2831\n",
      "Epoch 7/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3141 - val_loss: 0.2529\n",
      "Epoch 8/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2822 - val_loss: 0.2278\n",
      "Epoch 9/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2516 - val_loss: 0.2065\n",
      "Epoch 10/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2446 - val_loss: 0.1895\n",
      "Epoch 11/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2116 - val_loss: 0.1732\n",
      "Epoch 12/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2103 - val_loss: 0.1590\n",
      "Epoch 13/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2104 - val_loss: 0.1455\n",
      "Epoch 14/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1667 - val_loss: 0.1389\n",
      "Epoch 15/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1875 - val_loss: 0.1332\n",
      "Epoch 16/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1552 - val_loss: 0.1267\n",
      "Epoch 17/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1502 - val_loss: 0.1224\n",
      "Epoch 18/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1182\n",
      "Epoch 19/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1538 - val_loss: 0.1155\n",
      "Epoch 20/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1593 - val_loss: 0.1135\n",
      "Epoch 21/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1451 - val_loss: 0.1107\n",
      "Epoch 22/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1324 - val_loss: 0.1066\n",
      "Epoch 23/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1434 - val_loss: 0.1056\n",
      "Epoch 24/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1225 - val_loss: 0.1032\n",
      "Epoch 25/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1346 - val_loss: 0.1022\n",
      "Epoch 26/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1232 - val_loss: 0.1003\n",
      "Epoch 27/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1232 - val_loss: 0.0998\n",
      "Epoch 28/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1216 - val_loss: 0.0986\n",
      "Epoch 29/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1080 - val_loss: 0.0989\n",
      "Epoch 30/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1291 - val_loss: 0.0977\n",
      "Epoch 31/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1030 - val_loss: 0.0976\n",
      "Epoch 32/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1053 - val_loss: 0.0975\n",
      "Epoch 33/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0924 - val_loss: 0.0971\n",
      "Epoch 34/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1021 - val_loss: 0.0961\n",
      "Epoch 35/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1005 - val_loss: 0.0951\n",
      "Epoch 36/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0956 - val_loss: 0.0949\n",
      "Epoch 37/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0802 - val_loss: 0.0940\n",
      "Epoch 38/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0953 - val_loss: 0.0941\n",
      "Epoch 39/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0964 - val_loss: 0.0930\n",
      "Epoch 40/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.1007 - val_loss: 0.0926\n",
      "Epoch 41/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0895 - val_loss: 0.0932\n",
      "Epoch 42/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0939\n",
      "Epoch 43/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1171 - val_loss: 0.0931\n",
      "Epoch 44/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0872 - val_loss: 0.0916\n",
      "Epoch 45/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0682 - val_loss: 0.0932\n",
      "Epoch 46/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0874 - val_loss: 0.0944\n",
      "Epoch 47/600\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.0804 - val_loss: 0.0941\n",
      "Epoch 48/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0667 - val_loss: 0.0941\n",
      "Epoch 49/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.0966\n",
      "Epoch 50/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0843 - val_loss: 0.0967\n",
      "Epoch 51/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0580 - val_loss: 0.0960\n",
      "Epoch 52/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0862 - val_loss: 0.0949\n",
      "Epoch 53/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0710 - val_loss: 0.0944\n",
      "Epoch 54/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0678 - val_loss: 0.0944\n",
      "Epoch 55/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0604 - val_loss: 0.0946\n",
      "Epoch 56/600\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0663 - val_loss: 0.0946\n",
      "Epoch 57/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0747 - val_loss: 0.0943\n",
      "Epoch 58/600\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0523 - val_loss: 0.0959\n",
      "Epoch 59/600\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0883 - val_loss: 0.0932\n",
      "Epoch 60/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0771 - val_loss: 0.0821\n",
      "Epoch 61/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0749 - val_loss: 0.0806\n",
      "Epoch 62/600\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0693 - val_loss: 0.0814\n",
      "Epoch 63/600\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0486 - val_loss: 0.0813\n",
      "Epoch 64/600\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.0693 - val_loss: 0.0823\n",
      "Epoch 65/600\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0646 - val_loss: 0.0840\n",
      "Epoch 66/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0699 - val_loss: 0.0854\n",
      "Epoch 67/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.0869\n",
      "Epoch 68/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0626 - val_loss: 0.0889\n",
      "Epoch 69/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0528 - val_loss: 0.0895\n",
      "Epoch 70/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0683 - val_loss: 0.0896\n",
      "Epoch 71/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0663 - val_loss: 0.0890\n",
      "Epoch 72/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0567 - val_loss: 0.0897\n",
      "Epoch 73/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0494 - val_loss: 0.0909\n",
      "Epoch 74/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0534 - val_loss: 0.0928\n",
      "Epoch 75/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0489 - val_loss: 0.0933\n",
      "Epoch 76/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0842 - val_loss: 0.0889\n",
      "Epoch 77/600\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0867\n",
      "Epoch 78/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0450 - val_loss: 0.0859\n",
      "Epoch 79/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0417 - val_loss: 0.0853\n",
      "Epoch 80/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0568 - val_loss: 0.0861\n",
      "Epoch 81/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0454 - val_loss: 0.0876\n",
      "Epoch 82/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0661 - val_loss: 0.0894\n",
      "Epoch 83/600\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0703 - val_loss: 0.0900\n",
      "Epoch 84/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0608 - val_loss: 0.0897\n",
      "Epoch 85/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0491 - val_loss: 0.0893\n",
      "Epoch 86/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0540 - val_loss: 0.0884\n",
      "Epoch 86: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29d23ab30a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train,Y_train,epochs=600,validation_data=(X_test,Y_test),callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b18f0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossdf=pd.DataFrame(ann.history.history)\n",
    "lossdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54f57188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred=ann.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8905a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=Y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e862d50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.95      0.98        42\n",
      "         1.0       0.97      1.00      0.99        72\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00211913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c564eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904686b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac346a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005d63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692825a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c08c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
